{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python exercise 'estimate gradientâ€™ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "\n",
    "from scipy import stats \n",
    "from sklearn.datasets import make_regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick three vectors from the table, using letters from your names and using each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pick C, K and A from Cathy and Kai\n",
    "u = np.array([19., 41.]) # from C\n",
    "v = np.array([86., 6.])  # from K\n",
    "w = np.array([56., 20.]) # from A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the distance between two vectors as x, u as:\n",
    "Dist (x,u)= (x1-u1)^2+(x2-u2)^2\n",
    "\n",
    "Define the similarity function:\n",
    "Diff(x) = ln(1+Dist(u,x))+ln(1+Dist(v,x))+ln(1+Dist(w,x))\n",
    "\n",
    "Diff(x) is the distance between person x and your focus group of three people.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x,u):\n",
    "    #return (x[0]-u[0])**2 + (x[1]-u[1])**2\n",
    "    return np.sum((x - u) ** 2)\n",
    "\n",
    "def diff(x):\n",
    "    return np.log((1 + dist (u, x))) + np.log((1 + dist (v, x))) + np.log((1 + dist (w, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Diff(x) for 20 random points. \n",
    "\n",
    "What is the average value of Diff?\n",
    "What is the lowest and highest value you found?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.432541312892724, 27.2697312190068, 25.495868923511708, 24.115705859328756, 25.66897812793738, 26.021998594367712, 21.923568377587287, 25.753389577989367, 21.161884615870406, 20.203451456749683, 21.127786226948917, 21.411062587951918, 23.70277849050528, 19.561680342195643, 26.012782463313393, 23.128624296482254, 23.496383712659796, 19.815688294744128, 26.31414141777867, 26.456800081244168]\n",
      "Average: 23.6037422989533, Lowest Value: 19.561680342195643, Highest Value: 27.2697312190068\n"
     ]
    }
   ],
   "source": [
    "diffs = []\n",
    "\n",
    "for i in range(20):\n",
    "    #based on the values in the table I decided to pick a random number between 0 and 100\n",
    "    diffs.append(diff(np.array([float(random.randrange(100)), float(random.randrange(100))]))) \n",
    "\n",
    "print(diffs)\n",
    "print(f\"Average: {np.mean(diffs)}, Lowest Value: {min(diffs)}, Highest Value: {max(diffs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is random search a good way to minimize this function?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No.\n",
    "\n",
    "We have to hope that we randomly stumple across the vector with the minimum distance in our sample. \n",
    "\n",
    "We have no way of verifying if the lowest value we found is the minimum value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set x0=(50,50). Compute Diff(x)=Diff(50,50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50. 50.]\n",
      "21.873705514964627\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([50., 50.])\n",
    "diff_x0 = diff(x0)\n",
    "\n",
    "print(x0)\n",
    "print(diff_x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to compute and print the gradient of Diff by using a small delta=0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, delta=.001):\n",
    "    start = diff(x)\n",
    "    result = []\n",
    "    for i in range(len(x)):\n",
    "        #change each number in x by delta\n",
    "        x[i] += delta\n",
    "        step = diff(x)\n",
    "        result.append((step - start)/delta)\n",
    "        x[i] -= delta\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to print the gradient at (0,0), (100,0), (0,100) and (100,100). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at [0. 0.]\tis [-0.07340544 -0.05306046]\n",
      "Gradient at [100.   0.]\tis [ 0.17747654 -0.07856262]\n",
      "Gradient at [  0. 100.]\tis [-0.03222729  0.05906304]\n",
      "Gradient at [100. 100.]\tis [0.02978588 0.05175347]\n"
     ]
    }
   ],
   "source": [
    "points = np.array([[0., 0.],[100., 0.],[0., 100.],[100., 100.]])\n",
    "\n",
    "for point in points:\n",
    "    print(f\"Gradient at {point}\\tis {gradient(point)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on these values, where could be a minimum of Diff?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient at (0, 0), (0, 100) and (100, 100) is almost 0 so based on just the gradient any of these could be the minimum of Diff\n",
    "\n",
    "Or more acculately, the gradient at nnonne of these points is 0 so none of them are the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define xzero=(50,50) and stepsize=1.0. Make a function to compute xnext by taking e a small step into the opposite direction of the gradient, so that diff decreases. E.g. if the gradient is (0.4,0.6), do xnext=(oldx1-0.4*stepsize,oldx2-0.6*stepsize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49.         49.        ]\n",
      " [48.97584206 48.97584206]]\n"
     ]
    }
   ],
   "source": [
    "def xnext(x,stepsize):\n",
    "    start = gradient(x)\n",
    "    xnext = np.array([x-(start[0]*stepsize),x-(start[1]*stepsize)])\n",
    "    return xnext\n",
    "\n",
    "\n",
    "xzero = np.array([50,50])\n",
    "stepsize = 1\n",
    "print(xnext(xzero,stepsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
